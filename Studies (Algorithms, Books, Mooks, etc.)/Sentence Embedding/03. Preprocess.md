# 03. 한국어 전처리

## 데이터 확보

- 임베딩용 데이터는 직접 만들수도 있고 웹에서 스크래핑하는 방법도 있지만, 여기에서는 공개되어 있는 말뭉치 데이터를 활용
- [00. Environment](00.%20%Environment.md) 에서 만들어둔 docker 환경을 사용하며, 기본적으로 [git 환경](https://github.com/ratsgo/embedding.git)이 구축되어 있는 상태임

### 한국어 위키백과

- 한국어 위키백과의 원 데이터를 내려받는 코드는 `preprocess.sh`에 작성이 되어 있으므로 해당 파일을 `dump-raw-wiki` 명령어로 실행하고 전처리하여 원하는 형태의 데이터로 정리 

  ```bash
  git pull origin master
  bash preprocess.sh dump-raw-wiki
  bash preprocess.sh process-wiki
  ```

- 전처리 과정 중에 유용한 Regular expression은 아래와 같으며, `preprocess.sh`에 정의되어 있음:

  ```python
  import re
  
  WIKI_REMOVE_CHARS = re.compile("'+|(=+.{2,30}=+)|__TOC__|(ファイル:).+|:(en|de|it|fr|es|kr|zh|no|fi):|\n", re.UNICODE)
  
  WIKI_SPACE_CHARS = re.compile("(\\s|゙|゚|　)+", re.UNICODE)
  
  EMAIL_PATTERN = re.compile("(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$)", re.UNICODE)
  
  URL_PATTERN = re.compile("(ftp|http|https)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", re.UNICODE)
  
  WIKI_REMOVE_TOKEN_CHARS = re.compile("(\\*$|:$|^파일:.+|^;)", re.UNICODE)
  
  MULTIPLE_SPACES = re.compile(' +', re.UNICODE)
  ```

- 이 외 `wikiextractor` 또한 위키의 자료를 정리하는데 자주 사용되는 라이브러리로 다음의 ![링크](https://github.com/attardi/wikiextractor)에서 내용 확인 가능 

### KorQuAD
- [KorQuAD](https://korquad.gihub.io)는 한국어 기계독해를 위한 데이터 세트로 LG CNS가 구축하여 2018년에 공개 (70,079건)
- 질문과 답변 쌍을 사람들이 직접 만들어 둔 데이터로, 한국어 수능 지문과 유사한 형태의 구성을 갖추고 있음
- 마찬가지로 `preprocess.sh`에 데이터를 내려받고 정제하는 함수가 정의되어 있으므로 아래와 같이 실행 시 json 파일을 txt 파일로 정리:
```bash
git pull origin master
bash preprocess.sh dump-raw-korquad
bash preprocess.sh process-korquad
```

### 네이버 영화 리뷰 말뭉치
- [네이버의 영화 리뷰 말뭉치](https://github.com/e9t/nsmc)는 박은정님(lucypark)께서 구충하고 정제하여 공개한 말뭉치로, 감성분석 또는 문서분류에 제격인 데이터셋임
- 레코드 하나는 문서ID, 문서 내용, 1-0 레이블로 구성되어 있는 총 20만 세트의 tsv임
- 마찬가지로 `preprocess.sh`에 데이터를 내려받고 정제하는 함수가 정의되어 있으므로 아래와 같이 실행하여 전처리를 수행:
```bash
git pull origin master
bash preprocess.sh dump-raw-nsmc
bash preprocess.sh process-nsmc
```

### 전처리 완료 된 데이터 다운로드
- 위 내용을 참조하되, 아래와 같이 `preprocess.sh`를 실행하면, 전처리가 완료된 데이터셋을 한꺼번에 내려받을 수 있음
```bash
git pull origin master
bash preprocess.sh dump-processed
```
- 위 코드를 실행하면 모든 파일이 `/notebook/embedding/data/processed` 디렉터리에 저장되며, 파일 별 내용은 아래와 같음
  |파일명|내용|
  |---|---|
  |processed_wiki_ko.txt|한국어 위키백과|
  |processed_korquad.txt|KorQuAD 학습/데브세트|
  |processed_ratings.txt|네이버 영화 말뭉치 학습/테스트세트(극성레이블 없음)|
  |processed_ratings_train.txt|네이버 영화 말뭉치 학습세트(극성레이블 있음)|
  |processed_ratings_test.txt|네이버 영화 말뭉치 테스트세트(극성레이블 있음)|
  |space-correct.model|네이버 영화 말뭉치로 학습한 띄어쓰기 교정 모델|
  |corrected_ratings_train.txt|띄어쓰기 교정한 네이버 영화 말뭉치 학습세트(레이블 있음)|
  |corrected_ratings_test.txt|띄어쓰기 교정한 네이버 영화 말뭉치 테스트세트(레이블 있음)|
  |soyword.model|띄어쓰기 교정한 네이버 영화 말뭉치로 학습한 soynlp 형태소 분석 모델|
  |processed_review_movieid.txt|네이버 영화 말뭉치 전체 데이터세트(영화 ID 포함)|


##  지도 학습 기반 형태소 분석

### KoNLPy 사용법

### KoNLPy 내 분석기별 성능 차이 분석

### Khaiii 사용법

### 은전한닢에 사용자 사전 추가하기



## 비지도 학습 기반 형태소 분석

### soynlp 형태소 분석기

### 구글 센텐스피스

### 띄어쓰기 교정

### 형태소 분석 완료된 데이터 다운로드
