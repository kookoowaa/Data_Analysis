# 01. Embedding이란

- 자연어 처리에서 임베딩<sup>Embedding</sup>이란, 사람이 쓰는 자연어를 기계가 이해할 수 있는 **숫자의 나열**인 벡터<sup>Vector</sup> 공간에 "끼워 넣는다<sup>Embed</sup>"는 의미에서 유래됨
- 컴퓨터는 어디까지나 **계산기**일 뿐이기에, 자연어를 컴퓨터가 연산하고 처리할 수 있는 방식으로 치환해 주는 과정임

## 임베딩의 역할

### 단어/문장 간 관련도 계산

- 가장 단순한 형태의 임베딩은 **단어-문서 행렬<sup>Term-Document Matrix</sup>**로, 단어와 문서의 빈도 관계를 표현한 빈도표가 있음
- 현업에서 널리 알려진 임베딩 기법으로는 2013년 구글 연구팀이 발표한 **Word2Vec**이라는 기법이 있으며, 사람이 이해하기 어려운 고차원 (100개?) 벡터로 구성됨
- 단어를 벡터로 구성하게 되면, 벡터들 간에 유사도를 계산하는 것이 가능해지고, 보편적으로 **코사인 유사도<sup>cosine similarity</sup>**를 활용하여 유사도가 높은 벡터를 의미하는 단어를 역으로 추정하는 계산도 가능 (차원축소 및 시각화도 가능)

### 의미/문법 정보 함축

- 임베딩의 결과물인 벡터는 숫자로 이루어진 만큼, 사칙연산을 통해 단어 사이의 **의미/문법적 관계**를 도출하는 것도 가능
- 예를 들어 `아들 - 딸 + 소녀`연산의 결과인 벡터와 코사인 유사도가 가장 높은 단어가 `소년`과 같은 단어 유추평가가 성립된다면, 각 벡터 사이의 관계 및 의미 차이가 임베딩을 통해 벡터에 함축되어 있다고 볼 수 있음

### 전이 학습

- 임베딩 자체로도 위의 유추 평가 처럼 직접적으로 사용하기도 하지만, 임베딩 벡터를 입력값으로 하는 딥러닝 모델에서도 자주 사용됨; 이를 **전이학습<sup>transfer learning</sup>**이라고 함
- 전이 학습의 개념은, 마치 사람이 무언가를 배울 때 제로베이스에서 시작하지 않고 평생 쌓아온 지식을 바탕으로 새로운 사실을 빠르게 이해하듯이, 임베딩이라는 사전 지식을 활용하여 분류/예측/요약 등의 과제를 빠르고 잘 할 수 있게 도움을 줌

## 임베딩 기법의 역사

### 통계 기반에서 뉴럴 네트워크 기반으로

- 초기 임베딩 기법은 대부분 단어-문서 행렬 같은 통계량을 직접적으로 활용하는 기법에 의존적이었음
- 대표적인 기법이 **잠재 의미 분석<sup>Latent Semantic Analysis</sup>**로 거대한 **희소행렬<sup>sparse matrix</sup>**를 차원축소하여 단어 혹은 문서 수준의 임베딩을 구사하였음(**TF-IDF 행렬<sup>Term Frequency-Inverse Document Frequency</sup>, 단어-문맥 행렬<sup>Word-Context Matrix</sup>, 점별 상호 정보량 행렬<sup>Pointwise Mutual Information Matrix</sup>** 등 )
- 최근 임베딩 기법들은 뉴럴 네트워크 기반의 기법들이 주목받고 있음
- 뉴럴 네트워크는 그 구조가 유연하고 표현력이 풍부하기 때문에 자연어의 문맥을 상당 부분 효과적으로 학습할 수 있으며, 주로 **예측 과정에서 학습**을 진행하게 됨

### 단어 수준에서 문장 수준으로

- 2017년 이전의 임베딩 기법들은 **Word2Vec, GloVe**와 같은 단어 수준 모델이었으며, 단어의 벡터에 해당 단어의 문맥적 의미를 함축함 (동음이의어에 취약)
- 2018년 **ELMo<sup>Embeddings from Language Models</sup>** 발표 이후 단어 시퀀스 전체의 문맥적 의미를 함축하는 문장 수준의 임베딩 기법들이 주목받기 시작하였고, 최근 각광받는 **BERT<sup>Bidirectional Encoder Representations from Transformer</sup>**도 여기에 속함

### 규칙  설정 -> 엔드투엔드 -> 프리트레인/파인튜닝

- 90년대의 자연어 처리 모델은 대부분 사람이 피쳐를 직접 선정하고, 언어학적 지식을 갖춘 전문가가 **규칙<sup>rule</sup>**을 모델에 알려주는 방식이 주를 이루었음
- 2000년대 중반 이후 자연어 처리에서 딥러닝 모델이 주목받기 시작하였고, 데이터를 통째로 모델에 넣고 입출력 사이의 관계를 모델 스스로 학습하도록 유도하는 **엔드투엔드 모델<sup>end-to-end model</sup>**이 대표적이었음
- 2018년 **ELMo** 모델 이후

## 임베딩 기법의 종류



