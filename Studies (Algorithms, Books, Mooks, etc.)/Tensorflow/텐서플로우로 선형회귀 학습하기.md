# 텐서플로우로 선형회귀 학습하기

- 텐서플로우로 선형회귀를 학습하는 방법은 생각보다 단순함

  > 1. `tf.estimator.LinearRegressor()`로 선형 모델 생성
  > 2. 데이터를 입력하여 모델 학습 및 RMSE 계산
  > 3. 새로운 데이터(배치)로 추가 학습 및 RMSE 비교
  > 4. 주의할 점은 휴리스틱도 중요하지만, 데이터에 따라 선형 모델의 효과가 달라지므로 실험과 검증을 항상 반복

- 위 과정을 하나의 사용자 함수로 정리하면 다음과 같이 작성 가능:

  ```python
  def train_model(learning_rate, steps, batch_size, input_feature="total_rooms"):
    """Trains a linear regression model of one feature.
    
    Args:
      learning_rate: A `float`, the learning rate.
      steps: A non-zero `int`, the total number of training steps. A training step
        consists of a forward and backward pass using a single batch.
      batch_size: A non-zero `int`, the batch size.
      input_feature: A `string` specifying a column from `california_housing_dataframe`
        to use as input feature.
    """
    
    periods = 10
    steps_per_period = steps / periods
  
    my_feature = input_feature
    my_feature_data = california_housing_dataframe[[my_feature]]
    my_label = "median_house_value"
    targets = california_housing_dataframe[my_label]
  
    # Create feature columns.
    feature_columns = [tf.feature_column.numeric_column(my_feature)]
    
    # Create input functions.
    training_input_fn = lambda:my_input_fn(my_feature_data, targets, batch_size=batch_size)
    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)
    
    # Create a linear regressor object.
    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)
    linear_regressor = tf.estimator.LinearRegressor(
        feature_columns=feature_columns,
        optimizer=my_optimizer
    )
  
    # Set up to plot the state of our model's line each period.
    plt.figure(figsize=(15, 6))
    plt.subplot(1, 2, 1)
    plt.title("Learned Line by Period")
    plt.ylabel(my_label)
    plt.xlabel(my_feature)
    sample = california_housing_dataframe.sample(n=300)
    plt.scatter(sample[my_feature], sample[my_label])
    colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]
    
    """실질적인 모델링 구간"""
    # Train the model, but do so inside a loop so that we can periodically assess
    # loss metrics.
    print("Training model...")
    print("RMSE (on training data):")
    root_mean_squared_errors = []
    for period in range (0, periods):
      # Train the model, starting from the prior state.
      linear_regressor.train(
          input_fn=training_input_fn,
          steps=steps_per_period
      )
      # Take a break and compute predictions.
      predictions = linear_regressor.predict(input_fn=prediction_input_fn)
      predictions = np.array([item['predictions'][0] for item in predictions])
      
      # Compute loss.
      root_mean_squared_error = math.sqrt(
          metrics.mean_squared_error(predictions, targets))
      # Occasionally print the current loss.
      print("  period %02d : %0.2f" % (period, root_mean_squared_error))
      # Add the loss metrics from this period to our list.
      root_mean_squared_errors.append(root_mean_squared_error)
      # Finally, track the weights and biases over time.
      # Apply some math to ensure that the data and line are plotted neatly.
      y_extents = np.array([0, sample[my_label].max()])
      
      weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]
      bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')
  
      x_extents = (y_extents - bias) / weight
      x_extents = np.maximum(np.minimum(x_extents,
                                        sample[my_feature].max()),
                             sample[my_feature].min())
      y_extents = weight * x_extents + bias
      plt.plot(x_extents, y_extents, color=colors[period]) 
    print("Model training finished.")
  
    # Output a graph of loss metrics over periods.
    plt.subplot(1, 2, 2)
    plt.ylabel('RMSE')
    plt.xlabel('Periods')
    plt.title("Root Mean Squared Error vs. Periods")
    plt.tight_layout()
    plt.plot(root_mean_squared_errors)
  
    # Output a table with calibration data.
    calibration_data = pd.DataFrame()
    calibration_data["predictions"] = pd.Series(predictions)
    calibration_data["targets"] = pd.Series(targets)
    display.display(calibration_data.describe())
  
    print("Final RMSE (on training data): %0.2f" % root_mean_squared_error)
  ```

- 위 사용자 함수는 아래와 같이 실행하고 결과값을 추출할 수 있음:

  ```python
  train_model(
      learning_rate=0.00001,
      steps=100,
      batch_size=1
  )
  
  >>"""
    Training model...
    RMSE (on training data):
      period 00 : 236.32
      period 01 : 235.11
      period 02 : 233.90
      period 03 : 232.70
      period 04 : 231.50
      period 05 : 230.31
      period 06 : 229.13
      period 07 : 227.96
      period 08 : 226.79
      period 09 : 225.63
    Model training finished.
  
    Final RMSE (on training data): 225.63
  """
  ```

  