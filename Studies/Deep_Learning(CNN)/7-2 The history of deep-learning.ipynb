{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *딥러닝*\n",
    " ## 2. 딥러닝의 초기 역사\n",
    " \n",
    " - 딥러닝이 지금처럼 큰 주목을 받게 된 계기는 2012 이미지 인식 경선 ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 대회에서 거둔 AlexNet의 압도적이 성적 때문\n",
    " - 이후 대회의 주역은 항상 딥러닝이었음\n",
    " - 이하 최근의 딥러닝 트렌드에 대해 설명\n",
    " ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 이미지넷\n",
    "\n",
    "- **이미지넷(ImageNet)**은  100만장이 넘는 이미지를 담고 있는 데이터셋임\n",
    "- ILSVRC대회에서는 이 거대한 데이터셋을 활용하여 성능을 겨루며, 시험 항목 중 하나가 분류임\n",
    "-  2010년 부터 최근까지 ILSVRC의 분류(top-5 error: 상위 5개의 후보가 모두 오답인 경우) 우승 결과는 아래와 같음\n",
    "![](image/fig 8-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2012년 AlexNet이 오류율을 크게 낮췄고, 최근 150층이 넘는 심층 신경망인 ResNet이 오류율을 3.5% 까지 낮추며 인간의 인식 능력을 넘어섰다 평가받음\n",
    "- 최근 트렌드를 보면 VGG, GoogLeNet, ResNet이 유명하며, 다양한 딥러닝 분야에서 활용중\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) VGG\n",
    "- 2014년 대회에서 GoogLeNet에 이어 2위에 올랐으나, VGG는 구성이 간단한 만큼 많은 기술자가 용이하게 응용함\n",
    "![VGG](image/fig 8-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGG는 합성곱 계층과 풀링 계층으로 구성되는 '기본적'인 CNN임\n",
    "- 다만, 비중있는 층을 16층 혹은 19층으로 구분하여 심화한 것이 특징\n",
    "- 또한, 3 X 3의 작은 필터를 사용한 합성곱 계층을 연속으로 거침\n",
    "- 풀링 계층은 2~4회마다 두어 크기를 절반으로 줄임\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) GoogLeNet\n",
    "- GoogLeNet은 세로방향 깊이 뿐 아니라 가로 방향에도 폭이 있는 인셉션 구조를 가짐\n",
    "![GoogLeNet](image/fig 8-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본적으로는 지금까지 보아온 CNN과 다르지 않지만, GoogLeNet은 세로 뿐 아니라 가로 방향도 깊음\n",
    "![](image/fig 8-11.png)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) ResNet\n",
    "- ResNet(Residual Network)은 MS팀이 개발한 네트워크로 입력데이터를 출력데이터에 더하는 구조가 특징임\n",
    "![](image/fig 8-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적인 딥러닝의 경우 층이 지나치게 깊으면 학습이 잘 되지 않고 성능이 떨어지는 경우가 많음\n",
    "- 이를 개선하기 위해 **skip connection**을 도입, 입력데이터 $x$에 출력값 $F(x)$를 더하는 구조임\n",
    "![](image/fig 8-12.png)\n",
    "- 이로 인해 출력값이 기울기로 인해 지나치게 작아지거나 지나치게 커지는 현상을 방지하며 유의미한 기울기를 전달 (diminishing gradient 방지)\n",
    "- VGG를 기반으로 스킵 연결을 도입하여 층을 깊게 만듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
